\section{State Merklization}\label{sec:statemerklization}

The Merklization process defines a cryptographic commitment from which arbitrary information within state may be provided as being authentic in a concise and swift fashion. We describe this in two stages; the first defines a mapping from 32-octet sequences to (unlimited) octet sequences in a process called \emph{state serialization}. The second forms a 32-octet commitment from this mapping in a process called \emph{Merklization}.

\subsection{Serialization}

The serialization of state primarily involves placing all the various components of $\sigma$ into a single mapping from 32-octet sequence \emph{state-keys} to octet sequences of indefinite length. The state-key is constructed from a hash component and a chapter component, equivalent to either the index of a state component or, in the case of the inner dictionaries of $\delta$, a service index.

We define the state-key constructor functions $C$ as:
\begin{equation}
  C\colon\left\{\begin{aligned}
    \N_{2^8} \cup (\N_{2^8}, \N_S) \cup \tup{\N_S, \Y} &\to \H \\
    i \in \N_{2^8} &\mapsto [i, 0, 0, \dots] \\
    (i, s \in \N_S) &\mapsto [i, n_0, 0, n_1, 0, n_2, 0, n_3, 0, 0, \dots]\ \where n = \se_4(s) \\
    (s, h) &\mapsto [n_0, h_0, n_1, h_1, n_2, h_2, n_3, h_3, h_4, h_5, \dots, h_{27}]\ \where n = \se_4(s)
  \end{aligned}
  \right.
\end{equation}

The state serialization is then defined as the dictionary built from the amalgamation of each of the components. Cryptographic hashing ensures that there will be no duplicate state-keys given that there are no duplicate inputs to $C$. Formally, we define $T$ which transforms some state $\sigma$ into its serialized form:
\begin{equation}
  T(\sigma) \equiv \left\{\begin{aligned}
    &&C(1) &\mapsto \se([\var{x}\mid x\orderedin \alpha]) \;, \\
    &&C(2) &\mapsto \se(\varphi) \;, \\
    &&C(3) &\mapsto \se(\var{[(h, \se_M(\mathbf{b}), s, \var{\mathbf{p}})\mid (h, \mathbf{b}, s, \mathbf{p})\orderedin \beta]}) \;, \\
    &&C(4) &\mapsto \se\left(\tup{\gamma_\mathbf{k}, \gamma_z, \left\{\,\begin{aligned}
      0\ &\when \gamma_\mathbf{s} \in \seq{\mathbb{C}}_\mathsf{E}\\
      1\ &\when \gamma_\mathbf{s} \in \seq{\H_B}_\mathsf{E}\\
    \end{aligned}\right\}, \gamma_\mathbf{s},
    \var{\gamma_\mathbf{a}}}\right) \;, \\
    &&C(5) &\mapsto \se(\var{\orderby{x}{x \in \goodset}}, \var{\orderby{x}{x \in \badset}}, \var{\orderby{x}{x \in \wonkyset}}, \var{\orderby{x}{x \in \offenders}}) \;, \\
    &&C(6) &\mapsto \se(\eta) \;, \\
    &&C(7) &\mapsto \se(\iota) \;, \\
    &&C(8) &\mapsto \se(\kappa) \;, \\
    &&C(9) &\mapsto \se(\lambda) \;, \\
    &&C(10) &\mapsto \se([\maybe{(w, \se_4(t))} \mid (w, t) \orderedin \rho]) \;, \\
    &&C(11) &\mapsto \se_4(\tau) \;, \\
    &&C(12) &\mapsto \se_4(\chi_m, \chi_a, \chi_v) \concat \se(\chi_\mathbf{g}) \;, \\
    &&C(13) &\mapsto \se_4(\pi) \;, \\
    &&C(14) &\mapsto \se([\var{i} \mid i \orderedin \ready]) \;, \\
    &&C(15) &\mapsto \se(\accumulated) \;, \\
    \forall (s \mapsto \mathbf{a}) \in \delta: &&C(255, s) &\mapsto \mathbf{a}_c \concat \se_8(\mathbf{a}_b, \mathbf{a}_g, \mathbf{a}_m, \mathbf{a}_l) \concat \se_4(\mathbf{a}_i) \;, \\
    \forall (s \mapsto \mathbf{a}) \in \delta, (k \mapsto \mathbf{v}) \in \mathbf{a}_\mathbf{s}: &&C(s, \se_4(2^{32}-1) \frown k_{0\dots 28}) &\mapsto \mathbf{v} \;, \\
    \forall (s \mapsto \mathbf{a}) \in \delta, (h \mapsto \mathbf{p}) \in \mathbf{a}_\mathbf{p}: &&C(s, \se_4(2^{32}-2) \frown h_{1\dots 29}) &\mapsto \mathbf{p} \;, \\
    \forall (s \mapsto \mathbf{a}) \in \delta, (\tup{h, l} \mapsto \mathbf{t}) \in \mathbf{a}_\mathbf{l}: &&C(s, \se_4(l) \concat \mathcal{H}(h)) &\mapsto \se(\var{[\se_4(x) \mid x \orderedin \mathbf{t}]})
  \end{aligned}\right.
\end{equation}

Note that most rows describe a single mapping between key derived from a natural and the serialization of a state component. However, the final four rows each define sets of mappings since these items act over all service accounts and in the case of the final three rows, the keys of a nested dictionary with the service.

Also note that all non-discriminator numeric serialization in state is done in fixed-length according to the size of the term.

\subsection{Merklization}

With $T$ defined, we now define the rest of $\mathcal{M}_\sigma$ which primarily involves transforming the serialized mapping into a cryptographic commitment. We define this commitment as the root of the binary Patricia Merkle Trie with a format optimized for modern compute hardware, primarily by optimizing sizes to fit succinctly into typical memory layouts and reducing the need for unpredictable branching.

\subsubsection{Node Encoding and Trie Identification}
We identify (sub-)tries as the hash of their root node, with one exception: empty (sub-)tries are identified as the zero-hash, $\H^0$.

Nodes are fixed in size at 512 bit (64 bytes). Each node is either a branch or a leaf. The first bit discriminate between these two types.

In the case of a branch, the remaining 511 bits are split between the two child node hashes, using the last 255 bits of the 0-bit (left) sub-trie identity and the full 256 bits of the 1-bit (right) sub-trie identity.

Leaf nodes are further subdivided into embedded-value leaves and regular leaves. The second bit of the node discriminates between these.

In the case of an embedded-value leaf, the remaining 6 bits of the first byte are used to store the embedded value size. The following 31 bytes are dedicated to the first 31 bytes of the key. The last 32 bytes are defined as the value, filling with zeroes if its length is less than 32 bytes.

In the case of a regular leaf, the remaining 6 bits of the first byte are zeroed. The following 31 bytes store the first 31 bytes of the key. The last 32 bytes store the hash of the value.

Formally, we define the encoding functions $B$ and $L$:
\begin{align}
  B&\colon\left\{\begin{aligned}
    (\H, \H) &\to \mathbb{B}_{512}\\
    (l, r) &\mapsto [0] \frown \text{bits}(l)_{1\dots} \frown \text{bits}(r)
  \end{aligned}\right.\\
  L&\colon\left\{\begin{aligned}
    (\H, \Y) &\to \mathbb{B}_{512}\\
    (k, v) &\mapsto \begin{cases}
      [1, 0] \frown \text{bits}(\se_1(|v|))_{\dots6} \frown \text{bits}(k)_{\dots248} \frown \text{bits}(v) \frown [0, 0, \dots] &\when |v| \le 32\\
      [1, 1, 0, 0, 0, 0, 0, 0] \frown \text{bits}(k)_{\dots248} \frown \text{bits}(\mathcal{H}(v)) &\otherwise
    \end{cases}
  \end{aligned}\right.
\end{align}

We may then define the basic Merklization function $\mathcal{M}_\sigma$ as:
\begin{align}
  \mathcal{M}_\sigma(\sigma) &\equiv M(\{ (\text{bits}(k) \mapsto \tup{k, v}) \mid (k \mapsto v) \in T(\sigma) \})\\
  M(d: \dict{\mathbb{B}}{(\H, \Y)}) &\equiv \begin{cases}
    \H^0 &\when |d| = 0\\
    \mathcal{H}(\text{bits}^{-1}(L(k, v))) &\when \mathcal{V}(d) = \{ (k, v) \}\\
    \mathcal{H}(\text{bits}^{-1}(B(M(l), M(r)))) &\otherwise\\
    \multicolumn{2}{l}{\quad\where \forall b, p: (b \mapsto p) \in d \Leftrightarrow (b_{1\dots} \mapsto p) \in \begin{cases}
      l &\when b_0 = 0 \\
      r &\when b_0 = 1
    \end{cases}
  }\end{cases}
\end{align}

\section{General Merklization}\label{sec:merklization}

\subsection{Binary Merkle Trees}

The Merkle tree is a cryptographic data structure yielding a hash commitment to a specific sequence of values. It provides $O(N)$ computation and $O(\log(N))$ proof size for inclusion. This \emph{well-balanced} formulation ensures that the maximum depth of any leaf is minimal and that the number of leaves at that depth is also minimal.

The underlying function for our Merkle trees is the \emph{node} function $N$, which accepts some sequence of blobs of some length $n$ and provides either such a blob back or a hash:
\begin{equation}
  N\colon\left\{\begin{aligned}
    (\seq{\Y_n}, \Y \to \H) &\to \Y_n \cup \H \\
    (\mathbf{v}, H) &\mapsto \begin{cases}
      \H_0 &\when |\mathbf{v}| = 0 \\
      \mathbf{v}_0 &\when |\mathbf{v}| = 1 \\
      H(\token{\$node} \concat N(\mathbf{v}_{\dots\ceil{\nicefrac{|\mathbf{v}|}{2}}}, H) \concat N(\mathbf{v}_{\ceil{\nicefrac{|\mathbf{v}|}{2}}\dots}, H)) &\otherwise
    \end{cases}
  \end{aligned}\right.\label{eq:merklenode}
\end{equation}

The astute reader will realize that if our $\Y_n$ happens to be equivalent $\H$ then this function will always evaluate into $\H$. That said, for it to be secure care must be taken to ensure there is no possibility of preimage collision. For this purpose we include the hash prefix $\token{\$node}$ to minimize the chance of this; simply ensure any items are hashed with a different prefix and the system can be considered secure.

We also define the \emph{trace} function $T$, which returns each opposite node from top to bottom as the tree is navigated to arrive at some leaf corresponding to the item of a given index into the sequence. It is useful in creating justifications of data inclusion.
\begin{equation}
  T\colon\left\{\begin{aligned}
    (\seq{\Y_n}, \N_{|\mathbf{v}|}, \Y \to \H)\ &\to \seq{\Y_n \cup \H}\\
    (\mathbf{v}, i, H) &\mapsto \begin{cases}
      [N(P^\bot(\mathbf{v}, i), H)] \concat T(P^\top(\mathbf{v}, i), i - P_I(\mathbf{v}, i), H) &\when |\mathbf{v}| > 1\\
      [] &\otherwise\\
      \multicolumn{2}{l}{
        \begin{aligned}
          \quad \where P^s(\mathbf{v}, i) &\equiv \begin{cases}
            \mathbf{v}_{\dots\ceil{\nicefrac{|\mathbf{v}|}{2}}} &\when (i < \ceil{\nicefrac{|\mathbf{v}|}{2}}) = s\\
            \mathbf{v}_{\ceil{\nicefrac{|\mathbf{v}|}{2}}\dots} &\otherwise
          \end{cases}\\[4pt]
          \quad \also P_I(\mathbf{v}, i) &\equiv \begin{cases}
            0 &\when i < \ceil{\nicefrac{|\mathbf{v}|}{2}} \\
            \ceil{\nicefrac{|\mathbf{v}|}{2}} &\otherwise
          \end{cases}\\
        \end{aligned}
      }
    \end{cases}\\
  \end{aligned}\right.
\end{equation}

From this we define our other Merklization functions.

\subsubsection{Well-Balanced Tree}
We define the well-balanced binary Merkle function as $\mathcal{M}_B$:
\begin{equation}
    \mathcal{M}_B\colon \left\{\begin{aligned}\label{eq:simplemerkleroot}
      (\seq{\Y}, \Y \to \H) &\to \H \\
      (\mathbf{v}, H) &\mapsto \begin{cases}
        H(\mathbf{v}_0) &\when |\mathbf{v}| = 1 \\
        N(\mathbf{v}, H) &\otherwise
      \end{cases} \\
    \end{aligned}\right.
\end{equation}

This is suitable for creating proofs on data which is not much greater than 32 octets in length since it avoids hashing each item in the sequence. For sequences with larger data items, it is better to hash them beforehand to ensure proof-size is minimal since each proof will generally contain a data item.

Note: In the case that no hash function argument $H$ is supplied, we may assume the Blake 2b hash function, $\mathcal{H}$.

\subsubsection{Constant-Depth Tree}
We define the constant-depth binary Merkle function as $\mathcal{M}$ and the corresponding justification generation function as $\mathcal{J}$, with the latter having an optional subscript $x$, which limits the justification to only those nodes required to justify inclusion of a well-aligned subtree of (maximum) size $2^x$:
\begin{align}\label{eq:constantdepthmerkleroot}
  \mathcal{M}&\colon \left\{\begin{aligned}
    (\seq{\Y}, \Y \to \H) &\to \H\\
    (\mathbf{v}, H) &\mapsto N(C(\mathbf{v}, H), H)
  \end{aligned}\right.\\
  \mathcal{J}&\colon \left\{\begin{aligned}\label{eq:constantdepthmerklejust}
    (\seq{\Y}, \N_{|\mathbf{v}|}, \Y \to \H) &\to \seq{\H}\\
    (\mathbf{v}, i, H) &\mapsto T(C(\mathbf{v}, H), i, H)
  \end{aligned}\right.\\
  \mathcal{J}_x&\colon \left\{\begin{aligned}\label{eq:constantdepthsubtreemerklejust}
    (\seq{\Y}, \N_{|\mathbf{v}|}, \Y \to \H) &\to \seq{\H}\\
    (\mathbf{v}, i, H) &\mapsto T(C(\mathbf{v}, H), i, H)_{\dots\max(0, \ceil{\log_2(\max(1, |\mathbf{v}|)) - x})}
  \end{aligned}\right.
\end{align}

For the latter justification to be acceptable, we must assume the target observer knows not merely the value of the item at the given index, but also all other items within its $2^x$ size subtree.

As above, we may assume a default value for $H$ of the Blake 2b hash function, $\mathcal{H}$.

In all cases, a constancy preprocessor function $C$ is applied which hashes all data items with a fixed prefix and then pads them to the next power of two with the zero hash $\mathbb{H}_0$:
\begin{equation}
  C\colon\left\{\begin{aligned}
    (\seq{\Y}, \Y \to \H) &\to \seq{\H}\\
    (\mathbf{v}, H) &\mapsto \mathbf{v}' \ \where \left\{\; \begin{aligned}
      |\mathbf{v}'| &= 2^{\ceil{\log_2(\max(1, |\mathbf{v}|))}}\\
      \mathbf{v}'_i &= \begin{cases}
        H(\token{\$leaf}\frown\mathbf{v}_i) &\when i < |\mathbf{v}|\\
        \mathbb{H}_0 &\otherwise \\
      \end{cases}
    \end{aligned}\right.
  \end{aligned}\right.
\end{equation}

\subsection{Merkle Mountain Ranges}\label{sec:mmr}

The Merkle mountain range (\textsc{mmr}) is an append-only cryptographic data structure which yields a commitment to a sequence of values. Appending to an \textsc{mmr} and proof of inclusion of some item within it are both $O(\log(N))$ in time and space for the size of the set.

We define a Merkle mountain range as being within the set $\seq{\H?}$, a sequence of peaks, each peak the root of a Merkle tree containing $2^i$ items where $i$ is the index in the sequence. Since we support set sizes which are not always powers-of-two-minus-one, some peaks may be empty, $\none$ rather than a Merkle root.

Since the sequence of hashes is somewhat unwieldy as a commitment, Merkle mountain ranges are themselves generally hashed before being published. Hashing them removes the possibility of further appending so the range itself is kept on the system which needs to generate future proofs.

\newcommand*{\deffunc}[1]{\left\{\,\begin{aligned}#1\vphantom{x'_i}\end{aligned}\right.}

We define the append function $\mathcal{A}$ as:
\begin{equation}
  \begin{aligned}
    \label{eq:mmrappend}
    \mathcal{A}&\colon\deffunc{
      (\seq{\H?}, \H, \Y\to\H) &\to \seq{\H?}\\
      (\mathbf{r}, l, H) &\mapsto P(\mathbf{r}, l, 0, H)
    }\\
    \where P&\colon\deffunc{
      (\seq{\H?}, \H, \N, \Y\to\H) &\to \seq{\H?}\\
      (\mathbf{r}, l, n, H) &\mapsto \begin{cases}
        \mathbf{r} \doubleplus l &\when n \ge |\mathbf{r}|\\
        R(\mathbf{r}, n, l) &\when n < |\mathbf{r}| \wedge \mathbf{r}_n = \none\\
        P(R(\mathbf{r}, n, \none), H(\mathbf{r}_n \concat l), n + 1, H) &\otherwise
      \end{cases}
    }\\
    \also R&\colon\deffunc{
      (\seq{T}, \N, T) &\to \seq{T}\\
      (\mathbf{s}, i, v) &\mapsto \mathbf{s}'\ \where \mathbf{s}' = \mathbf{s} \exc \mathbf{s}'_i = v
    }
  \end{aligned}
\end{equation}

We define the \textsc{mmr} encoding function as $\se_M$:
\begin{equation}
  \se_M\colon\deffunc{
    \seq{\H?} &\to \Y \\
    \mathbf{b} &\mapsto \se(\var{[\maybe{x}\mid x \orderedin \mathbf{b}]})
  }
\end{equation}

%\begin{equation}
%  \left\{\mathbb{H}\right.
%\end{equation}
%\begin{equation}
%  \left\{\,\begin{aligned} & (\mathbb{H}) \\ & \begin{cases}x&y\end{cases} \end{aligned}\right.
%\end{equation}
