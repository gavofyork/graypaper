\section{Auditing and Judging}\label{sec:auditing}

The auditing and judging system is theoretically equivalent to that in \textsc{Elves}, introduced by \cite{cryptoeprint:2024/961}. For a full security analysis of the mechanism, see this work. There is a difference in terminology, where the terms \emph{backing}, \emph{approval} and \emph{inclusion} there refer to our guaranteeing, auditing and accumulation, respectively.

%The main point of divergence is in \Jam extending the utility of the availability system so that it does not simply serve auditing, but also allows data intentionally created as a side effect within a core to be utilized at some later stage without the requirement to re-insert it into the availability system. This creates additional bandwidth \emph{in to} the availability system for the importing of more such data. To maximize the value of this alteration, the expiry time of data entering the availability system is extended well beyond that which is needed for auditing, to 28 days.

\subsection{Overview}

The auditing process involves each node requiring themselves to fetch, evaluate and issue judgement on a random but deterministic set of work-reports from each \Jam chain block in which the work-report becomes available (\ie from $\mathbf{W}$). Prior to any evaluation, a node declares and proves its requirement. At specific common junctures in time thereafter, the set of work-reports which a node requires itself to evaluate from each block's $\mathbf{W}$ may be enlarged if any declared intentions are not matched by a positive judgement in a reasonable time or in the event of a negative judgement being seen. These enlargement events are called tranches.

If all declared intentions for a work-report are matched by a positive judgement at any given juncture, then the work-report is considered \emph{audited}. Once all of any given block's newly available work-reports are audited, then we consider the block to be \emph{audited}. One prerequisite of a node finalizing a block is for it to view the block as audited. Note that while there will be eventual consensus on whether a block is audited, there may not be consensus at the time that the block gets finalized. This does not affect the crypto-economic guarantees of this system.

In regular operation, no negative judgements will ultimately be found for a work-report, and there will be no direct consequences of the auditing stage. In the unlikely event that a negative judgement is found, then one of several things happens; if there are still more than $\nicefrac{2}{3}\mathsf{V}$ positive judgements, then validators issuing negative judgements may receive a punishment for time-wasting. If there are greater than $\nicefrac{1}{3}\mathsf{V}$ negative judgements, then the block which includes the work-report is ban-listed. It and all its descendants are disregarded and may not be built on. In all cases, once there are enough votes, a judgement extrinsic can be constructed by a block author and placed on-chain to denote the outcome. See section \ref{sec:disputes} for details on this.

All announcements and judgements are published to all validators along with metadata describing the signed material. On receipt of sure data, validators are expected to update their perspective accordingly (later defined as $J$ and $A$).

\subsection{Data Fetching}

For each work-report to be audited, we use its erasure-root to request erasure-coded chunks from enough assurers. From each assurer we fetch three items (which with a good network protocol should be done under a single request) corresponding to the work-package super-chunks, the self-justifying imports super-chunks and the extrinsic segments super-chunks.

We may validate the work-package reconstruction by ensuring its hash is equivalent to the hash includes as part of the work-package specification in the work-report. We may validate the extrinsic segments through ensuring their hashes are each equivalent to those found in the relevant work-item.

Finally, we may validate each imported segment as a justification must follow the concatenated segments which allows verification that each segment's hash is included in the referencing Merkle root and index of the corresponding work-item.

Exported segments need not be reconstructed in the same way, but rather should be determined in the same manner as with guaranteeing, \ie through the execution of the Refine logic.

All items in the work-package specification field of the work-report should be recalculated from this now known-good data and verified, essentially retracing the guarantors steps and ensuring correctness.

\subsection{Selection of Reports}

Each validator shall perform auditing duties on each valid block received. Since we are entering off-chain logic, and we cannot assume consensus, we henceforth consider ourselves a specific validator of index $v$ and assume ourselves focused on some block $\mathbf{B}$ with other terms corresponding, so $\sigma'$ is said block's posterior state, $\mathbf{H}$ is its header \etc Practically, all considerations must be replicated for all blocks and multiple blocks' considerations may be underway simultaneously.

We define the sequence of work-reports which we may be required to audit as $\mathbf{Q}$, a sequence of length equal to the number of cores, which functions as a mapping of core index to a work-report pending which has just become available, or $\none$ if no report became available on the core. Formally:
\begin{align}\label{eq:auditselection}
  \mathbf{Q} &\in \seq{\mathbb{W}?}_\mathsf{C} \\
  \mathbf{Q} &\equiv \left[\begin{rcases}
    \rho[c]_w &\when \rho[c]_w \in \mathbf{W} \\
    \none &\otherwise
  \end{rcases} \,\middle\vert\,c \orderedin \N_\mathsf{C}\right]
\end{align}

We define our initial audit tranche in terms of a verifiable random quantity $s_0$ created specifically for it:
\begin{align}
  s_0 &\in \bandersig{\kappa[v]_b}{\mathsf{X}_U \concat \banderout{\mathbf{H}_v}}{[]} \\
  \mathsf{X}_U &= \token{\$jam\_audit}
\end{align}

We may then define $\mathbf{a}_0$ as the non-empty items to audit through a verifiably random selection of ten cores:
\begin{align}
  \mathbf{a}_0 &= \{\tup{c, w} \mid \tup{c, w} \in \mathbf{p}_{\dots+10}, w \ne \none\} \\
  \where \mathbf{p} &= \mathcal{F}([\tup{c, \mathbf{Q}_c} \mid c \orderedin \N_\mathsf{C}], r) \\
  \also r &= \banderout{s_0}
\end{align}

Every $\mathsf{A} = 8$ seconds following a new time slot, a new tranche begins, and we may determine that additional cores warrant an audit from us. Such items are defined as $\mathbf{a}_n$ where $n$ is the current tranche. Formally:
\begin{equation}
  \using n = \ffrac{\mathcal{T} - \mathsf{P}\cdot\tau'}{\mathsf{A}}
\end{equation}

New tranches may contain items from $\mathbf{Q}$ stemming from one of two reasons: either a negative judgement has been received; or the number of judgements from the previous tranche is less than the number of announcements from said tranche. In the first case, the validator is always required to issue a judgement on the work-report. In the second case, a new special-purpose \textsc{vrf} must be constructed to determine if an audit and judgement is warranted from us.

In all cases, we publish a signed statement of which of the cores we believe we are required to audit (an \emph{announcement}) together with evidence of the \textsc{vrf} signature to select them and the other validators' announcements from the previous tranche unmatched with a judgement in order that all other validators are capable of verifying the announcement. \emph{Publication of an announcement should be taken as a contract to complete the audit regardless of any future information.}

Formally, for each tranche $n$ we ensure the announcement statement is published and distributed to all other validators along with our validator index $v$, evidence $s_n$ and all signed data. Validator's announcement statements must be in the set:
\begin{align}
  &\sig{\kappa[v]_e}{\mathsf{X}_I \doubleplus n \concat \se([\se_2(c) \frown \mathbf{H}(w) \mid \tup{c, w} \in \mathbf{a}_0])} \\
  &\mathsf{X}_I = \token{\$jam\_announce}
\end{align}

We define $A_n$ as our perception of which validator is required to audit each of the work-reports (identified by their associated core) at tranche $n$. This comes from each other validators' announcements (defined above). It cannot be correctly evaluated until $n$ is current. We have absolute knowledge about our own audit requirements.
\begin{align}
  A_n: \mathbb{W} &\to \powset{\N_\mathsf{V}} \\
  \forall (c, w) &\in \mathbf{a}_0 : v \in q_0(w)
\end{align}

We further define $J_\top$ and $J_\bot$ to be the validator indices who we know to have made respectively, positive and negative, judgements mapped from each work-report's core. We don't care from which tranche a judgement is made.
\begin{align}
  J_{\{\bot, \top\}}: \mathbb{W} \to \powset{\N_\mathsf{V}}
\end{align}

We are able to define $\mathbf{a}_n$ for tranches beyond the first on the basis of the number of validators who we know are required to conduct an audit yet from whom we have not yet seen a judgement. It is possible that the late arrival of information alters $\mathbf{a}_n$ and nodes should reevaluate and act accordingly should this happen.

We can thus define $\mathbf{a}_n$ beyond the initial tranche through a new \textsc{vrf} which acts upon the set of \emph{no-show} validators.
\begin{align}
  \nonumber&\!\!\!\!\!\!\!\!\forall n > 0:\\
  &\ s_n(w) \in \bandersig{\kappa[v]_b}{\mathsf{X}_U \concat \banderout{\mathbf{H}_v}\concat\mathcal{H}(w)\doubleplus n}{[]} \\
  &\ \mathbf{a}_n \equiv \{ w \in \mathbf{Q} \mid \textstyle\frac{\mathsf{V}}{256\mathsf{F}}\banderout{s_n(w)}_0 < |A_{n - 1}(w) \setminus J_\top(w)| \}\!\!\!\!
\end{align}

We define our bias factor $\mathsf{F} = 2$, which is the expected number of validators which will be required to issue a judgement for a work-report given a single no-show in the tranche before. Modeling by \cite{cryptoeprint:2024/961} shows that this is optimal.

Later audits must be announced in a similar fashion to the first. If audit requirements lessen on the receipt of new information (\ie a positive judgement being returned for a previous \emph{no-show}), then any audits already announced are completed and judgements published. If audit requirements raise on the receipt of new information (\ie an additional announcement being found without an accompanying judgement), then we announce the additional audit(s) we will undertake.

As $n$ increases with the passage of time $\mathbf{a}_n$ becomes known and defines our auditing responsibilities. We must attempt to reconstruct all work-packages and their requisite data corresponding to each work-report we must audit. This may be done through requesting erasure-coded chunks from one-third of the validators. It may also be short-cutted through asking a cooperative third-party (\eg an original guarantor) for the preimages.

Thus, for any such work-report $w$ we are assured we will be able to fetch some candidate work-package encoding $F(w)$ which comes either from reconstructing erasure-coded chunks verified through the erasure coding's Merkle root, or alternatively from the preimage of the work-package hash. We decode this candidate blob into a work-package.

In addition to the work-package, we also assume we are able to fetch all manifest data associated with it through requesting and reconstructing erasure-coded chunks from one-third of validators in the same way as above.

We then attempt to reproduce the report on the core to give $e_n$, a mapping from cores to evaluations: \vskip -7pt
\begin{equation}
  \begin{aligned}
  %  \forall (c, w) \in \mathbf{a}_n \!: e_n(w) \!\Leftrightarrow\! \begin{cases}
  %    w = \Xi(p, c)\!\!\!\!\! &\when \exists p \in \mathbb{P}: \se(p) = F(w) \\
  %    \bot &\otherwise
  %  \end{cases}
    \forall (c, w) \in \mathbf{a}_n :\ \ &\\[-10pt]
    e_n(w) \Leftrightarrow &\begin{cases}
      w = \Xi(p, c)\!\!\! &\when \exists p \in \mathbb{P}: \se(p) = F(w) \\
      \bot &\otherwise
    \end{cases}
  \end{aligned}\!\!
\end{equation}

Note that a failure to decode implies an invalid work-report.

From this mapping the validator issues a set of judgements $\mathbf{j}_n$:
\begin{align}
  \mathbf{j}_n &= \{ \mathcal{S}_{\kappa[v]_e}(\mathsf{X}_{e(w)} \concat \mathcal{H}(w)) \mid (c, w) \in \mathbf{a}_n \}
\end{align}

%We denote the guarantors of a work-package $w$ as $\mathbf{G}(w)$ from a particular chain head, and this may be derived from the guarantees extrinsic $\xtguarantees$ of the ancestor block which introduced the work-report. Our restrictions on the guarantees extrinsic (described in section \ref{sec:accumulation}) ensures that this is unique.
%\begin{equation}
%\begin{aligned}
%    \mathbf{G}(w) &\equiv [ v \mid (s, v) \orderedin a ] \\
%    \where (c, w, a) &\in \xtguarantees \\
%    (\mathbf{H}, \mathbf{E}) &\in \mathbf{A}
%\end{aligned}
%\end{equation}

All judgements $\mathbf{j}_*$ should be published to other validators in order that they build their view of $J$ and in the case of a negative judgement arising, can form an extrinsic for $\xtdisputes$.

We consider a work-report as audited under two circumstances. Either, when it has no negative judgements and there exists some tranche in which we see a positive judgement from all validators who we believe are required to audit it; or when we see positive judgements for it from greater than two-thirds of the validator set.
\begin{align}
%  U(w) &\Leftrightarrow J_\bot(w) = \emptyset \wedge \exists n : A_n(w) \subset J_\top(w) \vee |J_\top(w)| > \nicefrac{2}{3}\mathsf{V}%\!\!\!\!\!\!\!\!\!\!\!\!\!\!
  U(w) &\Leftrightarrow \bigvee\,\left\{\,\begin{aligned}
      &J_\bot(w) = \emptyset \wedge \exists n : A_n(w) \subset J_\top(w) \\
      &|J_\top(w)| > \nicefrac{2}{3}\mathsf{V}
  \end{aligned}\right.
\end{align}

Our block $\mathbf{B}$ may be considered audited, a condition denoted $\mathbf{U}$, when all the work-reports which were made available are considered audited. Formally:
\begin{align}
  \mathbf{U} &\Leftrightarrow \forall w \in \mathbf{W} : U(w)
\end{align}

For any block we must judge it to be audited (\ie $\mathbf{U} = \top$) before we vote for the block to be finalized in \textsc{Grandpa}. See section \ref{sec:grandpa} for more information here.

Furthermore, we pointedly disregard chains which include the accumulation of a report which we know at least $\nicefrac{1}{3}$ of validators judge as being invalid. Any chains including such a block are not eligible for authoring on. The \emph{best block}, \ie that on which we build new blocks, is defined as the chain with the most regular Safrole blocks which does \emph{not} contain any such disregarded block. Implementation-wise, this may require reversion to an earlier head or alternative fork.

As a block author, we include a judgement extrinsic which collects judgement signatures together and reports them on-chain. In the case of a non-valid judgement (\ie one which is not two-thirds-plus-one of judgements confirming validity) then this extrinsic will be introduced in a block in which accumulation of the non-valid work-report is about to take place. The non-valid judgement extrinsic removes it from the pending work-reports, $\rho$. Refer to section \ref{sec:disputes} for more details on this.

%Unselected work-reports may also be evaluated at a later stage if the node finds that auditing process does not complete adequately. Prior to evaluation of a report, the node announces its intention to audit along with a proof that the intention was derived honestly. Once fetched and evaluated, a judgement is published to all other validators.

%At its foundation this sequence is a random selection of an average of ten reports from each block. It is, however, affected by its perspective on the announcements and judgements of other nodes.

%If it does not see enough positive judgements on any given report, or it sees too many announcements with too few follow-up judgements, then it will eventually decide to conduct the audit itself.

%If an honest validator sees a judgement that a report is invalid it will prioritize the verification of said report and avert finalization of its block until it verifies the report itself.
